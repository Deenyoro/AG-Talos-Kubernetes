# librechat.yaml
# For more information, see:
# https://www.librechat.ai/docs/configuration/librechat_yaml

version: 1.2.1
cache: true

interface:
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: false
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true

registration:
  socialLogins: ["openid"]

speech:
  speechTab:
    conversationMode: false
    advancedMode: false
    speechToText:
      engineSTT: "external"
      languageSTT: "English (New Zealand)"
      autoTranscribeAudio: true
      decibelValue: -45
      autoSendText: 0
    textToSpeech:
      engineTTS: "external"
      voice: "alloy"
      languageTTS: "en"
      automaticPlayback: false
      playbackRate: 1.0
      cacheTTS: true
  tts:
    openai:
      apiKey: "$${SPEECH_API_KEY}"
      model: "tts-1"
      voices: ["alloy", "echo", "fable", "onyx", "nova", "shimmer"]
  stt:
    openai:
      apiKey: "$${SPEECH_API_KEY}"
      model: "whisper-1"

rateLimits:
  fileUploads:
    userMax: 50
    userWindowInMinutes: 60
  conversationsImport:
    ipMax: 100
    ipWindowInMinutes: 60
    userMax: 50
    userWindowInMinutes: 60

fileConfig:
  endpoints:
    assistants:
      disabled: false
    default:
      disabled: false
    openAI:
      disabled: false
    google:
      disabled: false
    anthropic:
      disabled: false
  serverFileSizeLimit: 200
  avatarSizeLimit: 2

endpoints:
  custom:
    - name: "Ollama"
      apiKey: "ollama"
      baseURL: "http://10.10.11.109:11434"
      models:
        default: [
          "deepseek-r1:14b",
          "deepseek-r1:8b"
        ]
        fetch: true
      titleConvo: true
      titleModel: "current_model"
      summarize: false
      summaryModel: "current_model"
      forcePrompt: false
      modelDisplayLabel: "Ollama"
      addParams: {} # Do not include extra parameters like max_tokens
  assistants:
    disableBuilder: false
    pollIntervalMs: 3000
    timeoutMs: 180000
  agents:
    disableBuilder: false
  all:
    streamRate: 35

modelSpecs:
  enforce: false
  prioritize: false
  list:
    - name: gpt-websearch-assistant
      label: Web Search
      description: This model can search the internet for information
      iconURL: "https://holmesazaepubshare.blob.core.windows.net/pub/chatgpt-yellowish.png"
      showIconInMenu: true
      showIconInHeader: true
      default: false
      preset:
        endpoint: assistants
        assistant_id: asst_kqHPerBQICFkmhyiLVsDV9JV
        modelLabel: Web Search
    - name: gpt-file-analyser
      label: File Analyser
      description: This model can run code to help interpret data you provide
      iconURL: "https://holmesazaepubshare.blob.core.windows.net/pub/chatgpt-purple.png"
      showIconInMenu: true
      showIconInHeader: true
      default: false
      preset:
        endpoint: assistants
        assistant_id: asst_bVWZWx9aJUwEAaLJFS1MLEju
        modelLabel: File Analyser
    - name: claude-3-7-sonnet
      label: Claude 3.7 Sonnet
      description: Claude is an equally capable alternative to ChatGPT, with a different personality and approach to conversation
      iconURL: "https://holmesazaepubshare.blob.core.windows.net/pub/claude.png"
      showIconInMenu: true
      showIconInHeader: true
      default: false
      preset:
        endpoint: anthropic
        model: claude-3-7-sonnet-20250219
        maxContextTokens: 200000
        max_tokens: 8192
        temperature: 0.7
        modelLabel: Claude
        greeting: "How can Claude help you today?"
        promptPrefix: "The assistant is Claude, created by Anthropic. ..."
    - name: claude-3-5-sonnet
      label: Claude
      description: Claude is an equally capable alternative to ChatGPT, with a different personality and approach to conversation
      iconURL: "https://holmesazaepubshare.blob.core.windows.net/pub/claude.png"
      showIconInMenu: true
      showIconInHeader: true
      default: false
      preset:
        endpoint: anthropic
        model: claude-3-5-sonnet-20241022
        maxContextTokens: 200000
        max_tokens: 8192
        temperature: 0.7
        modelLabel: Claude
        greeting: "How can Claude help you today?"
        promptPrefix: "The assistant is Claude, created by Anthropic. ..."
    - name: gpt-4o
      label: ChatGPT
      description: ChatGPT is great for general conversation and answering questions (via OpenAI)
      iconURL: "https://holmesazaepubshare.blob.core.windows.net/pub/chatgpt.png"
      showIconInMenu: true
      showIconInHeader: true
      default: false
      preset:
        endpoint: openAI
        model: chatgpt-4o-latest
        maxContextTokens: 128000
        max_tokens: 16384
        temperature: 0.7
        modelLabel: ChatGPT
        greeting: "Hi, I'm ChatGPT! How can I help you today?"
        promptPrefix: "You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture. ..."
    - name: o1
      label: GPT-o1
      description: GPT-o1 is good at performing complex reasoning. It's slower and more verbose than ChatGPT.
      showIconInMenu: true
      showIconInHeader: true
      default: false
      preset:
        endpoint: openAI
        model: o1
        maxContextTokens: 128000
        max_tokens: 32768
        temperature: 1
        modelLabel: GPT-o1
        greeting: "Ask me something complex!"
    - name: o1-preview
      label: GPT-o1 Preview
      description: GPT-o1 Preview version with potential new features
      showIconInMenu: true
      showIconInHeader: true
      default: false
      preset:
        endpoint: openAI
        model: o1-preview
        maxContextTokens: 128000
        max_tokens: 32768
        temperature: 1
        modelLabel: GPT-o1 Preview
        greeting: "Ask me something complex!"
    - name: gemini
      label: Gemini
      description: Gemini is useful when you want to process large amounts of data, up to 2,000 pages of text
      iconURL: "https://holmesazaepubshare.blob.core.windows.net/pub/gemini.png"
      showIconInMenu: true
      showIconInHeader: true
      default: false
      preset:
        endpoint: google
        model: gemini-2.0-flash-exp
        maxContextTokens: 1040000
        max_tokens: 8192
        temperature: 0.7
        modelLabel: Gemini
        greeting: "Gemini here, what can I do for you?"
    - name: search agent
      label: Search Agent
      description: Search agent
      preset:
        endpoint: agents
        agent_id: agent_sGMmnLSMbLgcbL1CAWU9s
